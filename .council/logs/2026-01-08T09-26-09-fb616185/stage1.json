{
  "responses": [
    {
      "model": "openai/gpt-5.2-pro",
      "response": "## 1. Summary\n\nThis commit introduces a \u201cMemory Blocks\u201d context assembly system (ADR-003 Phase 2) that structures LLM prompt context into five blocks (system/project/task/history/knowledge), enforces per-block and total token budgets via truncation/compression, and adds provenance support for retrieved knowledge/memories.\n\nKey components:\n- `src/memory/blocks/assembler.py`: builds blocks, compresses history, trims to a total budget, and (presumably) formats blocks into an XML-like prompt.\n- `src/memory/blocks/compressor.py`: compresses conversation history within a token budget.\n- `src/memory/blocks/schemas.py`: data models for blocks and provenance.\n- `src/memory/provenance/service.py`: in-memory provenance tracking service.\n- `src/memory/retrieval/ranker.py`: ranks memories and can attach provenance with retrieval scores.\n- `src/memory/evaluation/token_efficiency.py`: measures token usage vs baseline.\n\n## 2. Quality Assessment\n\n**Strengths**\n- Clear separation of concerns (schemas vs assembly vs compression vs provenance vs ranking).\n- Reasonably readable code with docstrings and typed signatures.\n- Budget trimming logic is straightforward and prioritized.\n\n**Maintainability concerns**\n- Several \u201ccorrectness invariants\u201d are documented but not enforced (e.g., \u201csystem never truncate\u201d).\n- Token counting is intentionally approximate, but some code treats it as \u201cstrictly enforced\u201d (misleading and error-prone).\n- Multiple places rely on message objects having `.role` / `.content`, but types are `Any` and common real-world inputs are dicts.\n\n## 3. Potential Issues (correctness/security/performance)\n\n### A) History compression mis-handles dict-based messages (likely real input) \u2014 **correctness bug**\n**File:** `src/memory/blocks/compressor.py` (approx lines 120\u2013150, `_format_messages`) and `summarize` (approx lines 95\u2013120)  \n```py\ncontent = getattr(msg, \"content\", str(msg))\nrole = getattr(msg, \"role\", \"unknown\")\n```\nIf `msg` is a dict like `{\"role\": \"user\", \"content\": \"hi\"}` (common for chat logs), `getattr` fails and falls back to `str(msg)`, producing:\n- role = `\"unknown\"`\n- content = `\"{'role': 'user', 'content': 'hi'}\"`\nThis corrupts both formatting and summarization, meaning the \u201chistory block\u201d will often be wrong.\n\n**Impact:** assembled context may become useless/noisy, and summarization will not reflect actual roles/contents.\n\n**Fix:** handle mappings explicitly, e.g.:\n```py\nif isinstance(msg, dict):\n    role = msg.get(\"role\", \"unknown\")\n    content = msg.get(\"content\", \"\")\nelse:\n    role = getattr(msg, \"role\", \"unknown\")\n    content = getattr(msg, \"content\", str(msg))\n```\n\n---\n\n### B) Per-block budgets are not consistently enforced \u2014 **correctness issue**\n**File:** `src/memory/blocks/assembler.py`\n- `build_project_block` does not enforce its budget (approx lines 95\u2013125).\n- `build_knowledge_block` does not enforce its budget (approx lines 185\u2013235).\n\nOnly `build_system_block` and `build_task_block` attempt truncation to their per-block budgets. History is budgeted via `HistoryCompressor(max_tokens=budget)`, but project/knowledge can exceed their budgets and only get trimmed later by total-budget trimming.\n\n**Impact:** block-level guarantees are unreliable; block assembly may overshoot total budget more often than expected, and the trimming step may truncate blocks you didn\u2019t intend to truncate first.\n\n**Fix:** apply `_truncate_preserving_format` in project/knowledge builders as well, using `self.block_budgets[BlockType.X]`.\n\n---\n\n### C) \u201cSystem block never truncate\u201d is contradicted by trimming logic \u2014 **correctness / invariant violation**\n**File:** `src/memory/blocks/schemas.py` (approx lines 125\u2013135) documents:\n```py\nBlockType.SYSTEM: 1,  # Core instructions - never truncate\n```\nBut `BlockAssembler._trim_to_budget` (approx lines 300\u2013345 in `assembler.py`) will truncate *any* block if the remaining budget can\u2019t fit it (including the system block), and can even exclude it entirely if `token_budget <= XML_OVERHEAD_PER_BLOCK` (because the partial-inclusion branch requires `remaining_budget > self.XML_OVERHEAD_PER_BLOCK`).\n\n**Impact:** under small token budgets, you can end up without system instructions or with truncated system policy\u2014dangerous for correctness and safety.\n\n**Fix options:**\n- Enforce a minimum token_budget that always fits the system block (and overhead), otherwise raise.\n- Or hard-pin system block inclusion, and trim others first; if system doesn\u2019t fit, raise.\n\n---\n\n### D) Token \u201cstrict enforcement\u201d is not actually strict (approximation + accounting gaps) \u2014 **correctness**\n**File:** `src/memory/blocks/assembler.py` `_truncate_preserving_format` (approx lines 345\u2013415)\n\nProblems:\n1) The token counter is a rough approximation (`HistoryCompressor.count_tokens`), yet docstrings claim \u201cRespects budget strictly.\u201d It won\u2019t.\n2) Marker handling can still overshoot:\n   - You reserve `marker_tokens`, but then append `\"\\n\" + truncation_marker` without accounting for the newline (with a real tokenizer it may matter).\n3) Word-based fallback uses:\n   ```py\n   max_words = int(effective_budget / 1.3)\n   return \" \".join(words[:max_words]) + \" \" + truncation_marker\n   ```\n   This can exceed `max_tokens` even under the same approximation because of rounding and the added marker/space.\n\n**Impact:** prompts may exceed budget/context window in production.\n\n**Fix:** either (a) use a real tokenizer, or (b) make truncation loop check actual `count_tokens(candidate)` after appending marker, and iterate down until it fits.\n\n---\n\n### E) Total budget vs per-block budgets + XML overhead are inconsistent \u2014 **correctness**\n**File:** `src/memory/blocks/assembler.py` `_calculate_total_with_overhead` (approx lines 270\u2013295)\n\nYou add `XML_OVERHEAD_PER_BLOCK = 15` per non-empty block to total cost. But:\n- The per-block budgets (`DEFAULT_TOKEN_BUDGETS`) sum to 5000, and `token_budget` default is 5000 too.\n- If all blocks are non-empty, overhead adds ~75 tokens, so you *always* exceed the total budget even when every block fits its own budget.\n\n**Impact:** unexpected trimming occurs even when \u201cwithin budget\u201d; hard to reason about output.\n\n**Fix options:**\n- Reduce default per-block budgets so that `sum(budgets) + overhead <= token_budget`.\n- Or incorporate overhead into each block\u2019s budget accounting.\n- Or don\u2019t treat wrapper overhead as tokens unless you measure it with the same tokenizer as the model.\n\n---\n\n### F) `TokenEfficiencyMetric` undercounts vs real prompt usage \u2014 **correctness**\n**File:** `src/memory/evaluation/token_efficiency.py` (approx lines 40\u201380)\n\nIt sums only `block.token_count` and ignores wrapper overhead entirely, while the assembler\u2019s true budget check includes overhead. This makes the efficiency metric systematically optimistic and not aligned with what\u2019s actually sent.\n\n**Fix:** measure the same thing you enforce\u2014either include overhead in the metric, or have assembler expose the final prompt token count.\n\n---\n\n### G) `MemoryRanker.calculate_recency` can divide by zero \u2014 **correctness bug**\n**File:** `src/memory/retrieval/ranker.py` (approx lines 85\u2013105)\n```py\ndecay_score = math.pow(0.5, age_days / self.decay_half_life_days)\n```\nIf `decay_half_life_days` is set to `0` (or negative), this will crash or behave incorrectly.\n\n**Fix:** validate in `__init__` (raise `ValueError` if <= 0 when decay is enabled).\n\n---\n\n### H) `MemoryRanker.calculate_score` doesn\u2019t clamp score to [0,1] \u2014 **correctness**\n**File:** `src/memory/retrieval/ranker.py` (approx lines 110\u2013130)\n\nIf callers pass weights that sum to > 1, or if `memory.confidence` is outside [0,1], the score can exceed 1.0. Some downstream code may assume a normalized score.\n\n**Fix:** validate weights and confidence range, and/or clamp final score.\n\n---\n\n### I) `rank_with_provenance` assumes `memory.metadata` exists and that `Memory` is Pydantic \u2014 **correctness risk**\n**File:** `src/memory/retrieval/ranker.py` (approx lines 160\u2013210)\n```py\nsource_id=memory.metadata.get(\"memory_id\", \"unknown\")\nmemory_with_provenance = memory.model_copy(update={\"provenance\": provenance})\n```\nIf `metadata` can be `None`, `.get` will fail. If `Memory` is not a Pydantic model (or doesn\u2019t implement `model_copy`), this will fail.\n\n**Fix:** guard `metadata` (`(memory.metadata or {})`) and/or avoid assuming Pydantic here (or enforce via type constraints).\n\n---\n\n### J) XML escaping incomplete and \u201cto_prompt\u201d usage not verifiable \u2014 **security/correctness risk**\n**File:** `src/memory/blocks/assembler.py` `_escape_xml_content` (approx lines 415\u2013445) and `to_prompt` (truncated)\n\nYou escape `&`, `<`, `>` which is the most important part for tag injection, but you do not escape quotes. That\u2019s usually okay **if** content is only used as element text, not attributes. However, since `to_prompt` is truncated, it\u2019s not possible to verify that `_escape_xml_content` is always applied and that content never lands in attributes.\n\n**Fix:** ensure `to_prompt` always escapes content; consider using a robust escaping utility (e.g., `xml.sax.saxutils.escape`) and keep content out of attributes.\n\n## 4. Recommendations\n\n1) **Fix dict message handling** in `HistoryCompressor` (`compress`, `_format_messages`, `summarize`) to correctly extract `role/content` for dicts. Add tests with both dict and object message formats.\n2) **Enforce per-block budgets consistently** (project + knowledge) and decide whether per-block budgets are hard limits or \u201csoft targets.\u201d\n3) **Make system block inclusion a hard invariant**: never drop it; raise if total budget cannot fit it.\n4) **Align budget accounting**:\n   - Either remove/replace the fixed `XML_OVERHEAD_PER_BLOCK` with measured tokenization,\n   - or adjust default budgets so overhead is accounted for.\n5) **Make truncation actually budget-safe** under your chosen tokenizer:\n   - Use a real tokenizer in production (tiktoken), or\n   - implement a post-check loop that ensures `count_tokens(result) <= max_tokens` even after markers.\n6) **Harden `MemoryRanker`**:\n   - validate `decay_half_life_days > 0` when decay enabled,\n   - validate/clamp weights and confidence,\n   - clamp final score to [0,1] if consumers assume that.\n7) **Update `TokenEfficiencyMetric`** to measure the same thing enforced by assembler (include overhead or measure final prompt).\n8) Add integration tests for `BlockAssembler.assemble()` that assert:\n   - total prompt tokens (including wrappers) never exceed `token_budget`,\n   - system block always present,\n   - dict-based chat history compresses correctly.\n\n## Verdict: **REJECTED**\n\nThere are multiple correctness-critical issues that can break real usage (notably dict message handling in history compression, inconsistent budget enforcement, and system block potentially being truncated/dropped under small budgets). These should be fixed before considering production readiness."
    },
    {
      "model": "google/gemini-3-pro-preview",
      "response": "Here is the review for commit `2d85a32`.\n\n### 1. Summary\nThe code implements the \"Memory Blocks\" architecture (ADR-003 Phase 2) designed to structure context for an LLM. It includes a `BlockAssembler` to manage five distinct context types (System, Project, Task, History, Knowledge) within a token budget. It also introduces a `HistoryCompressor` for summarization, a `ProvenanceService` for tracking data sources, and a `MemoryRanker` for retrieval scoring.\n\n### 2. Quality Assessment\n*   **Structure**: The code is well-modularized, separating assembly logic, compression, schemas, and scoring.\n*   **Readability**: Type hinting is consistent, and docstrings are descriptive. The separation of concerns (e.g., `ProvenanceService` vs. `BlockAssembler`) is cleanly implemented.\n*   **Safety**: The implementation includes XML escaping (`_escape_xml_content`) to prevent basic prompt injection attacks via retrieval content, which is a good security practice.\n*   **Extensibility**: The use of `Protocol` and `dataclass` makes the system easy to extend.\n\n### 3. Potential Issues\n\n#### Critical Correctness Issues\n\n**1. Loss of Formatting in History Compression** (`src/memory/blocks/compressor.py`)\nThe `_truncate_to_tokens` method in `HistoryCompressor` destroys non-space whitespace (newlines, tabs).\n*   **Location**: `src/memory/blocks/compressor.py` lines 122-132.\n*   **Problem**: `text.split()` splits on *any* whitespace sequence and discards the specific delimiter. `.join(words[:max_words])` joins them back with a single space.\n*   **Impact**: If a user's conversation history includes code blocks, bullet points, or paragraphs, they will be flattened into a single line if this truncation logic is triggered (which happens if `recent_text` exceeds budget or during general compression). This renders code in history largely unreadable to the LLM.\n\n**2. Token Counting Heuristic** (`src/memory/blocks/compressor.py`)\nThe token counting logic is a rough heuristic (`words * 1.3`).\n*   **Location**: `src/memory/blocks/compressor.py` line 66 (and used in `assembler.py`).\n*   **Impact**: While acknowledged in comments, for a system enforcing a \"Token Budget,\" this is risky. Code, URLs, and special characters often have a much higher token-to-word ratio than 1.3. This creates a correctness issue where the assembler *thinks* it is under budget (e.g., 5000 tokens) but sends a request that exceeds the model's actual context window, causing API failures.\n\n#### logic & Architectural Issues\n\n**3. Coupling of Priority and Prompt Order** (`src/memory/blocks/assembler.py`)\nThe `assemble` method sorts blocks by priority to determine which to truncate, but this sorted list is logically returned for prompt generation.\n*   **Location**: `src/memory/blocks/assembler.py` line 269 (`blocks.sort`) and line 271 (`_trim_to_budget`).\n*   **Problem**: High priority (System=1) implies \"keep this content\". However, if `to_prompt` (implied usage) iterates this list, it forces the prompt structure to be `System -> Project -> Task -> History -> Knowledge`.\n*   **Impact**: It is often desirable to place `History` or specific `Instruction` blocks at the very end of a prompt to overcome recency bias in LLMs. The current architecture forces the \"least valid to truncate\" blocks to appear first in the text, which limits prompt engineering flexibility.\n\n**4. Ranking Provenance Assumption** (`src/memory/retrieval/ranker.py`)\n*   **Location**: `src/memory/retrieval/ranker.py` line 186.\n*   **Problem**: The code calls `memory.model_copy(update={\"provenance\": provenance})`. This assumes the `Memory` object (imported from `src.memory.schemas`, not shown in review) has a `provenance` field or allows extra fields. If `Memory` is a strict Pydantic model defined in Phase 1 without this field, this line will raise a `ValidationError` at runtime.\n\n### 4. Recommendations\n\n1.  **Fix Whitespace Handling in Truncation**:\n    Modify `src/memory/blocks/compressor.py` to preserve formatting. Instead of `split()`/`join()`, verify tokens using a proper tokenizer (e.g., `tiktoken`) or, at minimum, split by lines first to preserve code block structure.\n    ```python\n    # Rough fix example\n    def _truncate_to_tokens(self, text: str, max_tokens: int) -> str:\n        # ... logic to truncate while preserving \\n ...\n    ```\n\n2.  **Improve Token Counting**:\n    Replace the `* 1.3` heuristic with a real tokenizer (e.g., `tiktoken`) simply wrapped in the compressor. This is critical for reliable operation near context limits.\n\n3.  **Decouple Assembly Order**:\n    In `BlockAssembler.assemble`, sort by priority for the *trimming* logic, but re-sort (or maintain a separate order index) for the functional *output* order.\n    ```python\n    # Example concept\n    blocks.sort(key=lambda b: b.priority)\n    blocks = self._trim_to_budget(blocks)\n    # Re-sort for display (e.g., System first, History last, irrespective of truncation priority)\n    blocks.sort(key=lambda b: getattr(b, 'display_order', 0))\n    ```\n\n4.  **Verify Memory Schema**:\n    Ensure `src.memory.schemas.Memory` has an Optional `provenance` field to support the ranking logic changes.\n\n### Verdict\n**NEEDS REVIEW**\n\nThe code is well-structured but contains a functional regression in `compressor.py` that destroys text formatting (newlines) in conversation history, which is critical for code-related contexts. Additionally, the token budget enforcement is loose due to the heuristic counter."
    },
    {
      "model": "anthropic/claude-opus-4.5",
      "response": "# Code Review: Memory Blocks Architecture (ADR-003 Phase 2)\n\n## Summary\n\nThis code implements a Memory Blocks architecture for structured context management in an LLM-based system. It provides:\n- Five functional memory block types (System, Project, Task, History, Knowledge)\n- A `BlockAssembler` that constructs context within token budgets\n- A `HistoryCompressor` for conversation history compression\n- Provenance tracking for retrieved content\n- Token efficiency metrics for measuring improvements\n- Memory ranking with combined scoring factors\n\n## Quality Assessment\n\n**Strengths:**\n- Well-documented with clear docstrings and ADR references\n- Good separation of concerns across modules\n- Type hints throughout\n- Appropriate use of dataclasses and enums\n- Good test coverage implied by the structure\n\n**Weaknesses:**\n- Several correctness issues identified below\n- Some inconsistencies in async/sync usage\n- Token counting is approximation-based (acknowledged in comments)\n\n## Potential Issues\n\n### Critical Issues\n\n#### 1. **Memory Schema Missing `provenance` Field** (`src/memory/retrieval/ranker.py`, line 187)\n\n```python\nmemory_with_provenance = memory.model_copy(\n    update={\"provenance\": provenance}\n)\n```\n\nThe `Memory` schema (referenced from `src/memory/schemas`) likely doesn't have a `provenance` field, which would cause a Pydantic validation error at runtime. The `MemoryBlock` has provenance, but `Memory` is a different class.\n\n**Impact:** Runtime crash when `rank_with_provenance` is called with `attach_provenance=True`.\n\n#### 2. **XML Escaping Not Applied in `to_prompt`** (`src/memory/blocks/assembler.py`)\n\nThe `_escape_xml_content` method is defined but never called in `to_prompt`:\n\n```python\ndef to_prompt(self, blocks: list[MemoryBlock]) -> str:\n    # ... content is used directly without escaping\n    parts.append(f\"<{tag}>\\n{block.content}\\n</{tag}>\")\n```\n\nThis creates a **prompt injection vulnerability** where malicious content containing `</system>` or similar tags could break the XML structure or manipulate the prompt.\n\n**Impact:** Security vulnerability - potential prompt injection attacks.\n\n### Moderate Issues\n\n#### 3. **Inconsistent Token Budget Enforcement** (`src/memory/blocks/assembler.py`, lines 112-121)\n\nIn `build_project_block`, there's no token budget enforcement, unlike `build_system_block` and `build_task_block`:\n\n```python\nasync def build_project_block(self, user_id: str) -> MemoryBlock:\n    content = f\"Project context for user {user_id}.\"\n    token_count = self._count_tokens(content)\n    # No budget check here!\n    return MemoryBlock(...)\n```\n\n**Impact:** Project blocks could potentially exceed their budget when populated with real data.\n\n#### 4. **Race Condition in Provenance Service** (`src/memory/provenance/service.py`, lines 87-99)\n\nThe `track_retrieval` method has a check-then-act pattern that's not atomic:\n\n```python\nif memory_id in self._provenance_store:\n    existing = self._provenance_store[memory_id]\n    updated = replace(existing, retrieval_score=retrieval_score)\n    self._provenance_store[memory_id] = updated\n```\n\nIn concurrent scenarios, this could lead to lost updates.\n\n**Impact:** Potential data inconsistency in concurrent environments.\n\n#### 5. **Empty Query Still Creates Provenance** (`src/memory/blocks/assembler.py`, lines 185-198)\n\nWhen query is empty, `build_knowledge_block` returns early with no provenance, but when query is non-empty, provenance is always created with placeholder data. The early return path has inconsistent behavior:\n\n```python\nif not query:\n    return MemoryBlock(\n        # ... no provenance\n    )\n# else creates provenance with hardcoded confidence=1.0\n```\n\n**Impact:** Inconsistent provenance tracking; hardcoded confidence of 1.0 is misleading.\n\n### Minor Issues\n\n#### 6. **Token Counting Approximation Drift** (`src/memory/blocks/compressor.py`, lines 47-56)\n\nThe word-based token approximation (`len(words) * 1.3`) and its inverse (`max_tokens / 1.3`) can drift:\n\n```python\ndef count_tokens(self, text: str) -> int:\n    return int(len(words) * 1.3)\n\ndef _truncate_to_tokens(self, text: str, max_tokens: int) -> str:\n    max_words = int(max_tokens / 1.3)\n```\n\nWith `int()` truncation on both sides, the inverse operation doesn't perfectly reverse, potentially allowing slightly more tokens than the budget.\n\n#### 7. **Unused Protocol** (`src/memory/blocks/compressor.py`, lines 22-26)\n\nThe `Message` Protocol is defined but never used for type checking:\n\n```python\nclass Message(Protocol):\n    role: str\n    content: str\n```\n\nThe `compress` method accepts `list[Any]` instead of `list[Message]`.\n\n#### 8. **Missing Validation for Confidence Score** (`src/memory/provenance/service.py`, line 53)\n\n```python\nasync def create_provenance(\n    self,\n    confidence: float,  # No validation for 0.0-1.0 range\n```\n\nThe docstring states confidence should be 0.0-1.0, but this isn't enforced.\n\n## Recommendations\n\n1. **Fix XML escaping** - Call `_escape_xml_content` in `to_prompt`:\n   ```python\n   escaped_content = self._escape_xml_content(block.content)\n   parts.append(f\"<{tag}>\\n{escaped_content}\\n</{tag}>\")\n   ```\n\n2. **Add provenance field to Memory schema** or create a wrapper type for ranked results that includes provenance.\n\n3. **Apply consistent budget enforcement** across all `build_*_block` methods.\n\n4. **Use asyncio.Lock** or make the ProvenanceService thread-safe if concurrent access is expected.\n\n5. **Validate confidence scores** in `create_provenance`:\n   ```python\n   if not 0.0 <= confidence <= 1.0:\n       raise ValueError(\"Confidence must be between 0.0 and 1.0\")\n   ```\n\n6. **Use the Message Protocol** or remove it to avoid confusion.\n\n7. **Consider using tiktoken** for production token counting (as noted in code comments).\n\n## Verdict\n\n**NEEDS REVIEW**\n\nThe critical issue with missing XML escaping (prompt injection vulnerability) and the likely schema mismatch in `rank_with_provenance` need to be verified and fixed before production deployment. The architecture is sound, but these correctness issues could cause runtime failures or security vulnerabilities.\n\n**Required fixes before approval:**\n1. Verify and fix the `Memory` schema provenance field issue\n2. Apply XML content escaping in `to_prompt` method\n3. Add consistent budget enforcement to `build_project_block`"
    },
    {
      "model": "x-ai/grok-4",
      "response": "### Code Review for Commit `2d85a32`\n\n#### 1. Summary\nThis code implements Phase 2 of the Memory Blocks architecture (as per ADR-003) for structured context management in an AI system. It defines five functional memory blocks (System, Project, Task, History, Knowledge) for efficient LLM context assembly within token budgets. Key components include:\n- **Block Assembler** (`assembler.py`): Builds and assembles blocks, handles token budgeting, truncation, and XML formatting for prompts.\n- **History Compressor** (`compressor.py`): Compresses conversation history by preserving recent messages and summarizing older ones to improve token efficiency.\n- **Schemas** (`schemas.py`): Defines enums, dataclasses, and defaults for block types, provenance, and budgets.\n- **Provenance Service** (`service.py`): Tracks source attribution and retrieval events for memories, meeting ADR-003's provenance requirement.\n- **Token Efficiency Metric** (`token_efficiency.py`): Measures token usage against a baseline to verify 30% efficiency improvement.\n- **Memory Ranker** (`ranker.py`): Ranks memories using similarity, recency (with decay), and confidence; supports provenance attachment.\n- Supporting init files for module organization.\n\nThe implementation focuses on token-efficient context engineering, with placeholders for production integrations (e.g., actual data retrieval).\n\n#### 2. Quality Assessment\n- **Code Quality**: The code is well-structured, modular, and adheres to Python best practices (e.g., type hints, dataclasses, enums). Docstrings are comprehensive, referencing ADRs and GitHub issues, which aids understanding. Consistent naming (e.g., `build_*_block` methods) and separation of concerns (e.g., compressor vs. assembler) enhance clarity. XML escaping in `assembler.py` (line ~300, in `_escape_xml_content`) shows attention to security in prompt generation.\n- **Readability**: High readability due to clear comments, short methods, and logical flow. For example, the assembler's `assemble` method (line ~250) sequentially builds blocks and trims them, making it easy to follow. Approximations (e.g., token counting in `compressor.py` line 50) are explicitly noted as placeholders for production (e.g., using `tiktoken`).\n- **Maintainability**: Excellent, with configurable defaults (e.g., `DEFAULT_TOKEN_BUDGETS` in `schemas.py` line 130), extensibility (e.g., weights in `ranker.py` init), and test-friendly design (e.g., async methods for future concurrency). In-memory storage in `service.py` is simple but noted as such, allowing easy replacement with a database.\n\nOverall, the code scores highly (8/10) but could benefit from more robust error handling and real tokenizers for production readiness.\n\n#### 3. Potential Issues\nFocusing on correctness (as per the review instructions), I identified several concerns related to logical accuracy, budget enforcement, and incomplete implementations. No critical security vulnerabilities were found beyond what's already mitigated (e.g., XML escaping prevents prompt injection). Performance is fine for the scale (in-memory operations, simple algorithms), but approximations could lead to inefficiencies in large-scale use.\n\n- **Correctness Issues**:\n  - **Inaccurate Token Counting**: The token counter in `compressor.py` (line 50) and `assembler.py` (line 75) uses a rough approximation (words * 1.3), which may under- or overestimate tokens (e.g., for dense text or special characters). This could lead to incorrect budgeting in `assemble` (line ~250) or truncation in `_trim_to_budget` (line ~320), causing overruns or unnecessary cuts. For models like GPT, this isn't precise\u2014correctness fails if actual tokens exceed budgets.\n  - **Truncation Logic Flaws**: In `assembler.py`'s `_truncate_preserving_format` (line ~350), the method reserves tokens for a truncation marker (\"...\") but adds it with a newline (\"\\n\" + marker), which isn't accounted for in the effective budget. This could cause slight overruns (e.g., if the newline adds 1-2 tokens). Additionally, if the first line exceeds the budget, it falls back to word truncation, but the max_words calculation (int(effective_budget / 1.3)) reverses the approximation incorrectly, potentially leading to over-truncation.\n  - **Placeholder Implementations Affecting Correctness**: \n    - `build_project_block` (line ~110) and `build_knowledge_block` (line ~200) use static placeholders instead of actual data fetching. While noted as such, this means the blocks don't correctly represent real project/knowledge context, violating ADR-003's intent for accurate context engineering.\n    - In `compressor.py`'s `summarize` (line 120), the \"summary\" is just a concatenation of first sentences, which may not correctly capture key points (e.g., misses context from longer messages). This could lead to loss of important history, affecting response accuracy.\n  - **Provenance Handling**: In `ranker.py`'s `rank_with_provenance` (line ~220), it attaches provenance using `memory.model_copy(update={\"provenance\": provenance})`, but the `Memory` schema (imported from `src.memory.schemas`) isn't provided in this commit. If `Memory` lacks a `provenance` field, this will raise an AttributeError\u2014correctness issue unless the schema is updated elsewhere.\n  - **Recency Calculation**: In `ranker.py`'s `calculate_recency` (line 100), if `last_accessed_at` is in the future (e.g., due to clock skew), `age_days` becomes negative, but it's clamped to 0 (correct). However, without decay, it uses linear decay over 90 days, which might not align with ADR-003's emphasis on exponential decay for realism.\n  - **Budget Merging**: In `assembler.py` init (line 60), merging `block_budgets` with defaults is correct, but if `block_budgets` omits a `BlockType`, it falls back to default (good). However, no validation ensures budgets sum to `token_budget`, potentially leading to implicit overruns before trimming.\n\n- **Security Vulnerabilities**: Low risk. XML escaping in `assembler.py` (line ~300) mitigates injection, but if user-input content (e.g., in `task_context`) contains unescaped XML, it could still break prompts if not consistently applied (though it is in `to_prompt`).\n\n- **Performance Concerns**: \n  - Simple similarity in `ranker.py` (line 70, Jaccard overlap) is O(n) but inefficient for large `memories` lists due to set operations per memory. For thousands of memories, this could be slow without optimization.\n  - In-memory stores in `service.py` (line 40) could consume excessive memory for high-volume retrieval tracking, but it's fine for this phase.\n\nNo outright bugs that crash the code, but the approximations and placeholders reduce correctness in real scenarios.\n\n#### 4. Recommendations\n- **Improve Token Accuracy**: Replace the approximate counter with a real tokenizer like `tiktoken` (e.g., in `compressor.py` line 50 and `assembler.py` line 75). Add a comment: \"TODO: Integrate model-specific tokenizer for production.\"\n- **Enhance Truncation**: In `assembler.py`'s `_truncate_preserving_format` (line ~350), account for the newline token cost in effective_budget. Add unit tests for edge cases (e.g., single-line overflow).\n- **Replace Placeholders**: Implement actual data fetching in `build_project_block` (line ~110) and `build_knowledge_block` (line ~200), e.g., integrate with a database or API. For summaries in `compressor.py` (line 120), use an LLM for better accuracy.\n- **Validate Schemas**: Ensure `Memory` in `ranker.py` (line ~220) includes a `provenance` field; if not, add it to `src.memory.schemas` for consistency with `blocks.schemas.Provenance`.\n- **Add Error Handling**: In `assemble` (line ~250), handle cases where total_tokens still exceeds budget after trimming (e.g., log a warning). Validate inputs (e.g., ensure `token_budget > 0` in init).\n- **Testing and Metrics**: Add unit tests for ranking (e.g., verify decay in `ranker.py` line 100) and efficiency (e.g., ensure `token_efficiency.py` line 50 correctly flags <30% improvement). Consider integrating with the provenance service in the assembler for full traceability.\n- **Optimization**: For `ranker.py`, cache similarity computations or use embeddings (e.g., cosine similarity) for better correctness in semantic matching.\n\nThese changes would boost correctness without major rewrites.\n\n#### Verdict\n**NEEDS REVIEW**  \nThe code correctly implements the core architecture and meets ADR-003's structural requirements (e.g., blocks, provenance, efficiency metrics), but placeholders, approximate token counting, and potential schema mismatches introduce correctness risks in production use. I recommend a human review to verify integrations (e.g., actual data fetching) and add tests before approval."
    }
  ],
  "usage": {
    "prompt_tokens": 39987,
    "completion_tokens": 16162,
    "total_tokens": 56149
  },
  "timestamp": "2026-01-08T09:30:03.997507"
}